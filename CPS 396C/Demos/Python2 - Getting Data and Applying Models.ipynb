{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Data and Applying Models\n",
    "=====\n",
    "\n",
    "Some of the code contained within this notebook is from Ch. 9 of *Data Science from Scratch* by J. Grus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "Let's grab some text from the web and then determine the most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 \tthe\n",
      "112 \ti\n",
      "107 \tof\n",
      "99 \tand\n",
      "99 \tto\n",
      "88 \tmy\n",
      "79 \ta\n",
      "62 \tin\n",
      "38 \twhich\n",
      "37 \tthat\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import urllib2\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for line in urllib2.urlopen('http://www.gutenberg.org/files/84/84-0.txt').read(20000).split(\"\\n\"):\n",
    "\n",
    "    counter += Counter(word.lower() for word in line.strip().split() if word)\n",
    "    \n",
    "for word, count in counter.most_common(10):\n",
    "    print count, \"\\t\", word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization and JSON\n",
    "\n",
    "Python supports json, javascript object notation.  Files containing json can be read and written with `load` and `dump`.  These require a file pointer.  `loads` and '`dumps` work with strings.  \n",
    "\n",
    "Serialization is one way to port objects or dump custom data structures.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n",
      "<type 'str'> {\"a\": 5, \"the\": 32}\n",
      "<type 'dict'> {u'a': 5, u'the': 32}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "serialized = \"\"\"{ \"title\" : \"Data Science Book\",\n",
    "                      \"author\" : \"Joel Grus\",\n",
    "                      \"publicationYear\" : 2014,\n",
    "                      \"topics\" : [ \"data\", \"science\", \"data science\"] }\"\"\"\n",
    "\n",
    "# Load the object ...\n",
    "deserialized = json.loads(serialized)\n",
    "\n",
    "print type(deserialized)\n",
    "\n",
    "# Encode a dictionary and list, then decode ...\n",
    "\n",
    "counts = {'the': 32, 'a': 5}\n",
    "nums = [1, 2, 3]\n",
    "\n",
    "### Solution ###\n",
    "encoded = json.dumps(counts)\n",
    "print type(encoded), encoded\n",
    "\n",
    "decoded = json.loads(encoded)\n",
    "print type(decoded), decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of what can be stored in json, let's inspect something taken from Twitter [Link](https://gist.githubusercontent.com/hrp/900964/raw/2bbee4c296e6b54877b537144be89f19beff75f4/twitter.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n",
      "[u'user', u'favorited', u'retweeted_status', u'entities', u'contributors', u'truncated', u'text', u'created_at', u'retweeted', u'in_reply_to_status_id_str', u'coordinates', u'id', u'source', u'in_reply_to_status_id', u'in_reply_to_screen_name', u'in_reply_to_user_id', u'place', u'retweet_count', u'geo', u'in_reply_to_user_id_str', u'id_str']\n",
      "OldGREG85\n",
      "{\n",
      "    \"contributors\": null, \n",
      "    \"coordinates\": null, \n",
      "    \"created_at\": \"Sun Apr 03 23:48:36 +0000 2011\", \n",
      "    \"entities\": {\n",
      "        \"hashtags\": [], \n",
      "        \"urls\": [], \n",
      "        \"user_mentions\": [\n",
      "            {\n",
      "                \"id\": 271572434, \n",
      "                \"id_str\": \"271572434\", \n",
      "                \"indices\": [\n",
      "                    3, \n",
      "                    19\n",
      "                ], \n",
      "                \"name\": \"PostGradProblems\", \n",
      "                \"screen_name\": \"PostGradProblem\"\n",
      "            }\n",
      "        ]\n",
      "    }, \n",
      "    \"favorited\": false, \n",
      "    \"geo\": null, \n",
      "    \"id\": 54691802283900930, \n",
      "    \"id_str\": \"54691802283900928\", \n",
      "    \"in_reply_to_screen_name\": null, \n",
      "    \"in_reply_to_status_id\": null, \n",
      "    \"in_reply_to_status_id_str\": null, \n",
      "    \"in_reply_to_user_id\": null, \n",
      "    \"in_reply_to_user_id_str\": null, \n",
      "    \"place\": null, \n",
      "    \"retweet_count\": 4, \n",
      "    \"retweeted\": false, \n",
      "    \"retweeted_status\": {\n",
      "        \"contributors\": null, \n",
      "        \"coordinates\": null, \n",
      "        \"created_at\": \"Sun Apr 03 20:24:49 +0000 2011\", \n",
      "        \"entities\": {\n",
      "            \"hashtags\": [\n",
      "                {\n",
      "                    \"indices\": [\n",
      "                        130, \n",
      "                        134\n",
      "                    ], \n",
      "                    \"text\": \"PGP\"\n",
      "                }\n",
      "            ], \n",
      "            \"urls\": [], \n",
      "            \"user_mentions\": []\n",
      "        }, \n",
      "        \"favorited\": false, \n",
      "        \"geo\": null, \n",
      "        \"id\": 54640519019642880, \n",
      "        \"id_str\": \"54640519019642881\", \n",
      "        \"in_reply_to_screen_name\": null, \n",
      "        \"in_reply_to_status_id\": null, \n",
      "        \"in_reply_to_status_id_str\": null, \n",
      "        \"in_reply_to_user_id\": null, \n",
      "        \"in_reply_to_user_id_str\": null, \n",
      "        \"place\": null, \n",
      "        \"retweet_count\": 4, \n",
      "        \"retweeted\": false, \n",
      "        \"source\": \"<a href=\\\"http://www.hootsuite.com\\\" rel=\\\"nofollow\\\">HootSuite</a>\", \n",
      "        \"text\": \"In preparation for the NFL lockout, I will be spending twice as much time analyzing my fantasy baseball team during company time. #PGP\", \n",
      "        \"truncated\": false, \n",
      "        \"user\": {\n",
      "            \"contributors_enabled\": false, \n",
      "            \"created_at\": \"Thu Mar 24 19:45:44 +0000 2011\", \n",
      "            \"default_profile\": true, \n",
      "            \"default_profile_image\": false, \n",
      "            \"description\": \"\", \n",
      "            \"favourites_count\": 0, \n",
      "            \"follow_request_sent\": null, \n",
      "            \"followers_count\": 3066, \n",
      "            \"following\": null, \n",
      "            \"friends_count\": 21, \n",
      "            \"geo_enabled\": false, \n",
      "            \"id\": 271572434, \n",
      "            \"id_str\": \"271572434\", \n",
      "            \"is_translator\": false, \n",
      "            \"lang\": \"en\", \n",
      "            \"listed_count\": 6, \n",
      "            \"location\": \"\", \n",
      "            \"name\": \"PostGradProblems\", \n",
      "            \"notifications\": null, \n",
      "            \"profile_background_color\": \"C0DEED\", \n",
      "            \"profile_background_image_url\": \"http://a3.twimg.com/a/1301071706/images/themes/theme1/bg.png\", \n",
      "            \"profile_background_tile\": false, \n",
      "            \"profile_image_url\": \"http://a2.twimg.com/profile_images/1285770264/PGP_normal.jpg\", \n",
      "            \"profile_link_color\": \"0084B4\", \n",
      "            \"profile_sidebar_border_color\": \"C0DEED\", \n",
      "            \"profile_sidebar_fill_color\": \"DDEEF6\", \n",
      "            \"profile_text_color\": \"333333\", \n",
      "            \"profile_use_background_image\": true, \n",
      "            \"protected\": false, \n",
      "            \"screen_name\": \"PostGradProblem\", \n",
      "            \"show_all_inline_media\": false, \n",
      "            \"statuses_count\": 31, \n",
      "            \"time_zone\": null, \n",
      "            \"url\": null, \n",
      "            \"utc_offset\": null, \n",
      "            \"verified\": false\n",
      "        }\n",
      "    }, \n",
      "    \"source\": \"<a href=\\\"http://twitter.com/\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\", \n",
      "    \"text\": \"RT @PostGradProblem: In preparation for the NFL lockout, I will be spending twice as much time analyzing my fantasy baseball team during ...\", \n",
      "    \"truncated\": true, \n",
      "    \"user\": {\n",
      "        \"contributors_enabled\": false, \n",
      "        \"created_at\": \"Tue Oct 06 01:13:17 +0000 2009\", \n",
      "        \"default_profile\": true, \n",
      "        \"default_profile_image\": false, \n",
      "        \"description\": \"watcha doin in my waters?\", \n",
      "        \"favourites_count\": 0, \n",
      "        \"follow_request_sent\": null, \n",
      "        \"followers_count\": 48, \n",
      "        \"following\": null, \n",
      "        \"friends_count\": 81, \n",
      "        \"geo_enabled\": false, \n",
      "        \"id\": 80177619, \n",
      "        \"id_str\": \"80177619\", \n",
      "        \"is_translator\": false, \n",
      "        \"lang\": \"en\", \n",
      "        \"listed_count\": 0, \n",
      "        \"location\": \"Texas\", \n",
      "        \"name\": \"GG\", \n",
      "        \"notifications\": null, \n",
      "        \"profile_background_color\": \"C0DEED\", \n",
      "        \"profile_background_image_url\": \"http://a3.twimg.com/a/1300479984/images/themes/theme1/bg.png\", \n",
      "        \"profile_background_tile\": false, \n",
      "        \"profile_image_url\": \"http://a1.twimg.com/profile_images/455128973/gCsVUnofNqqyd6tdOGevROvko1_500_normal.jpg\", \n",
      "        \"profile_link_color\": \"0084B4\", \n",
      "        \"profile_sidebar_border_color\": \"C0DEED\", \n",
      "        \"profile_sidebar_fill_color\": \"DDEEF6\", \n",
      "        \"profile_text_color\": \"333333\", \n",
      "        \"profile_use_background_image\": true, \n",
      "        \"protected\": false, \n",
      "        \"screen_name\": \"OldGREG85\", \n",
      "        \"show_all_inline_media\": false, \n",
      "        \"statuses_count\": 351, \n",
      "        \"time_zone\": \"Hawaii\", \n",
      "        \"url\": null, \n",
      "        \"utc_offset\": -36000, \n",
      "        \"verified\": false\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# https://gist.githubusercontent.com/hrp/900964/raw/2bbee4c296e6b54877b537144be89f19beff75f4/twitter.json\n",
    "import json\n",
    "import urllib2\n",
    "\n",
    "serialized = \"\"\n",
    "\n",
    "for line in urllib2.urlopen('https://gist.githubusercontent.com/hrp/900964/raw/2bbee4c296e6b54877b537144be89f19beff75f4/twitter.json'):\n",
    "    serialized += line\n",
    "\n",
    "# print serialized\n",
    "# print type(serialized)\n",
    "\n",
    "tweet = json.loads(serialized)\n",
    "print type(tweet)\n",
    "print tweet.keys()\n",
    "print tweet[\"user\"][\"screen_name\"]\n",
    "\n",
    "print json.dumps(tweet, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Load a dataset over house prices in Boston.  Houses are characterized by 13 features.  These a positive, real valued and the target is value (in thousands of dollars). [Boston Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "<type 'numpy.ndarray'>\n",
      "(506,)\n",
      "[6.320e-03 1.800e+01 2.310e+00 0.000e+00 5.380e-01 6.575e+00 6.520e+01\n",
      " 4.090e+00 1.000e+00 2.960e+02 1.530e+01 3.969e+02 4.980e+00] 24.0\n",
      "Ranges [8.896988e+01 1.000000e+02 2.728000e+01 1.000000e+00 4.860000e-01\n",
      " 5.219000e+00 9.710000e+01 1.099690e+01 2.300000e+01 5.240000e+02\n",
      " 9.400000e+00 3.965800e+02 3.624000e+01]\n",
      "Max. per feature [ 88.9762 100.      27.74     1.       0.871    8.78   100.      12.1265\n",
      "  24.     711.      22.     396.9     37.97  ]\n",
      "Min. per feature [6.3200e-03 0.0000e+00 4.6000e-01 0.0000e+00 3.8500e-01 3.5610e+00\n",
      " 2.9000e+00 1.1296e+00 1.0000e+00 1.8700e+02 1.2600e+01 3.2000e-01\n",
      " 1.7300e+00]\n",
      "Mean. per feature [3.61352356e+00 1.13636364e+01 1.11367787e+01 6.91699605e-02\n",
      " 5.54695059e-01 6.28463439e+00 6.85749012e+01 3.79504269e+00\n",
      " 9.54940711e+00 4.08237154e+02 1.84555336e+01 3.56674032e+02\n",
      " 1.26530632e+01]\n",
      "Std. per feature [8.59304135e+00 2.32993957e+01 6.85357058e+00 2.53742935e-01\n",
      " 1.15763115e-01 7.01922514e-01 2.81210326e+01 2.10362836e+00\n",
      " 8.69865112e+00 1.68370495e+02 2.16280519e+00 9.12046075e+01\n",
      " 7.13400164e+00]\n",
      "[-0.41978194 -0.48772236 -1.55784179 -0.27259857 -1.46588193 -3.88024936\n",
      " -2.33543704 -1.26706919 -0.98284286 -1.31399004 -2.70737911 -3.9071933\n",
      " -1.5311271 ] [9.9339306  3.80423444 2.42256516 3.66839786 2.73234648 3.55504427\n",
      " 1.11749449 3.96051769 1.66124525 1.79819419 1.63882832 0.44105193\n",
      " 3.54877081]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.data.shape)\n",
    "print(type(boston.data))\n",
    "print(boston.target.shape)\n",
    "\n",
    "print boston.data[0,:], boston.target[0]\n",
    "\n",
    "# Determine the range of each feature\n",
    "X = boston.data\n",
    "\n",
    "### Solution ###\n",
    "print \"Ranges\", np.max(X, axis=0) - np.min(X, axis=0)\n",
    "print \"Max. per feature\", np.max(X, axis=0)\n",
    "print \"Min. per feature\", np.min(X, axis=0)\n",
    "print \"Mean. per feature\", np.mean(X, axis=0)\n",
    "print \"Std. per feature\", np.std(X, axis=0)\n",
    "\n",
    "# Normalize with z scores\n",
    "X = boston.data\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "print np.min(X, axis=0), np.max(X, axis=0)\n",
    "\n",
    "\n",
    "# Normalize by scaling\n",
    "X = boston.data\n",
    "rnge = (np.max(X, axis=0) - np.min(X, axis=0))\n",
    "X = (X - np.min(X, axis=0))\n",
    "X = X / rnge\n",
    "\n",
    "print np.min(X, axis=0), np.max(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in CSV Files\n",
    "\n",
    "Data can readily be saved and accessed from comma seperated value files (CSV).  \n",
    "\n",
    "Each line corresponds to one record, with individual fields separated by commas.  The first line may contain a header.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "# https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "boston = np.genfromtxt('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# print boston\n",
    "# print boston.shape\n",
    "# print boston[0,:]\n",
    "\n",
    "X = boston[:,:13] #For every row, get the first 13 columns\n",
    "Y = boston[:,13]\n",
    "\n",
    "print X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.426 0.283 0.   ]\n",
      " [0.244 0.827 1.   ]\n",
      " [0.485 0.661 1.   ]\n",
      " ...\n",
      " [0.248 0.566 1.   ]\n",
      " [0.884 0.196 0.   ]\n",
      " [0.931 0.919 0.   ]]\n",
      "[0. 1. 1. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This is the game data from Jack and Jill.  There first two columns are the plays of Jack and Jill\n",
    "#   and the third column is the winner.\n",
    "\n",
    "# Read in data and save to X, y\n",
    "\n",
    "### Solution ###\n",
    "data = np.genfromtxt('http://mlid.cps.cmich.edu/resources/game-data.txt', delimiter = ' ')\n",
    "print data\n",
    "\n",
    "X = data[:,:2]\n",
    "Y = data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have a model parameterized by a middle layer with 2 nodes and 1 output node.  We will use a sigmoid activation function.  Apply the model to our game data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.60522265],\n",
       "        [0.60713222],\n",
       "        [0.60785989],\n",
       "        ...,\n",
       "        [0.60562946],\n",
       "        [0.60794918],\n",
       "        [0.61243735]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"Numerically stable sigmoid function.\"\n",
    "    if x >= 0:\n",
    "        z = math.exp(-x)\n",
    "        return 1 / (1 + z)\n",
    "    else:\n",
    "        # if x is less than zero then z will be small, denom can't be\n",
    "        # zero because it's 1+z.\n",
    "        z = math.exp(x)\n",
    "        return z / (1 + z)\n",
    "\n",
    "def NN_apply(X, W1, B1, W2, B2):\n",
    "    \"Do a feed-forward pass through a neural network\"\n",
    "    A1 = np.dot(X, W1) + B1\n",
    "    Z1 = np.vectorize(sigmoid)(A1)\n",
    "\n",
    "    A2 = np.dot(Z1, W2) + B2\n",
    "    Z2 = np.vectorize(sigmoid)(A2)\n",
    "\n",
    "    return Z2\n",
    "\n",
    "W1 = np.matrix([[0.2, 0.2], [0.1, 0.3]])  # Were did these values come from ???\n",
    "B1 = np.matrix([[0.05, 0.05]])\n",
    "W2 = np.matrix([[0.4], [0.2]])\n",
    "B2 = np.matrix([[0.1]])\n",
    "\n",
    "NN_apply(X, W1, B1, W2, B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the accuracy of the predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4969\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "# Generate predictions ...\n",
    "model_output = NN_apply(X, W1, B1, W2, B2)\n",
    "\n",
    "# Initialize predictions to 0, then determine indices of predictions that are \n",
    "#  above the 0.5 threshold\n",
    "predictions = np.zeros(model_output.shape)\n",
    "predictions[model_output > 0.5] = 1\n",
    "\n",
    "correct_count = 0\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == Y[i]:\n",
    "        correct_count += 1\n",
    "        \n",
    "### Determine the accuracy of the predicitons\n",
    "print correct_count / predictions.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow we would like to adjust the weights to improve the performace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch  1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1e37dc3dcc9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mYt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# ???\n",
    "\n",
    "mid_layer_size = 2\n",
    "epochs = 10\n",
    "batch_size = 20\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initialize some random values for the weights in the NN\n",
    "W1 = np.random.rand(X.shape[1], int(mid_layer_size))\n",
    "W1 = 0.01 * W1\n",
    "B1 = np.random.rand(1, int(mid_layer_size))\n",
    "B1 = 0.01 * B1\n",
    "\n",
    "W2 = np.random.rand(int(mid_layer_size), 1)\n",
    "W2 = 0.01 * W2\n",
    "B2 = np.random.rand(1,1)\n",
    "B2 = 0.01 * B2\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * sigmoid(1-x)\n",
    "\n",
    "def evaluate(X, Y):\n",
    "    \" calculate the accuracy of the model \"\n",
    "    O = NN_apply(X, W1, B1, W2, B2)\n",
    "\n",
    "    P = np.zeros(O.shape)\n",
    "    for i in range(P.shape[0]):\n",
    "        if O[i] > 0.5:\n",
    "            P[i] = 1\n",
    "\n",
    "    correct_count = 0\n",
    "    for i in range(P.shape[0]):\n",
    "        if abs(Y[i] - P[i]) < 0.001:\n",
    "               correct_count = correct_count + 1\n",
    "\n",
    "    print \"Accuracy \", 1.0 * correct_count / Y.shape[0]\n",
    "\n",
    "\n",
    "for i in range(0, epochs):\n",
    "    print \"Starting epoch \", i + 1\n",
    "\n",
    "    for j in range(0, X.shape[0] // batch_size):\n",
    "\n",
    "        Xt = X[j*batch_size:(j+1)*batch_size,:]\n",
    "        Yt = y[j*batch_size:(j+1)*batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        A1 = np.dot(Xt, W1) + B1\n",
    "        Z1 = np.vectorize(sigmoid)(A1)\n",
    "\n",
    "        A2 = np.dot(Z1, W2) + B2\n",
    "        Z2 = np.vectorize(sigmoid)(A2)\n",
    "        \n",
    "        # Calculate D\n",
    "        D2 = (Z2 - np.reshape(Yt, (Z2.shape[0],1))) * np.vectorize(sigmoid_prime)(A2)\n",
    "        D1 = np.dot(D2, np.transpose(W2))  * np.vectorize(sigmoid_prime)(A1)\n",
    "\n",
    "        DE_dw2 = np.dot(np.transpose(Z1) , D2)               \n",
    "        DE_dw1 = np.dot(np.transpose(Xt) , D1)\n",
    "\n",
    "        # Update weights               \n",
    "\n",
    "        W2 = W2 - learning_rate * DE_dw2 \n",
    "        W1 = W1 - learning_rate * DE_dw1\n",
    "        B2 = B2 - learning_rate * np.dot(np.ones((1, D2.shape[0])), D2)\n",
    "        B1 = B1 - learning_rate * np.dot(np.ones((1, D1.shape[0])), D1)\n",
    "        \n",
    "    evaluate(X, y)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
