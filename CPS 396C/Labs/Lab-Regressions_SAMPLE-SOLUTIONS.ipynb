{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressions\n",
    "=====\n",
    "\n",
    "**Objective**: Create models based on regression and perform feature selection.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_NAME = \"Dr. E\" # <-- Your name here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a) Construct a linear regression using all of the features from the Boston Housing dataset.  Evaluate the model using a holdout dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training:  0.7337556403947554\n",
      "Mean diffference on training:  3.3105184155364853\n",
      "Score on validation:  -0.21985315040420383\n",
      "Mean diffference on validation:  4.730017250960962\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_difference(a, b):\n",
    "    return np.sqrt(np.square((a - b))).sum() / a.shape[0]\n",
    "\n",
    "### Bring in the Boston Housing Dataset\n",
    "from sklearn.datasets import load_boston\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "#print type(X), X.shape, type(y), y.shape\n",
    "N = int(0.8 * X.shape[0])\n",
    "train_X = X[:N,:]\n",
    "train_y = y[:N]\n",
    "val_X = X[N:,:]\n",
    "val_y = y[N:]\n",
    "\n",
    "### Use sklearn's LinearRegression module \n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(train_X, train_y)\n",
    "\n",
    "### Evaluate the performance with score, mean difference\n",
    "train_y_hat = reg.predict(train_X)\n",
    "val_y_hat = reg.predict(val_X)\n",
    "\n",
    "print \"Score on training: \", reg.score(train_X, train_y)\n",
    "print \"Mean diffference on training: \", mean_difference(train_y, train_y_hat)\n",
    "print \"Score on validation: \", reg.score(val_X, val_y)\n",
    "print \"Mean diffference on validation: \", mean_difference(val_y, val_y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b) Look at the coeffiencts of the model.  Are the interpretable?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  1.59090124e-01 -2.77864862e-05]\n",
      "1.3351635361410872\n"
     ]
    }
   ],
   "source": [
    "### ADDED\n",
    "print reg.coef_\n",
    "print reg.intercept_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Perform a feature selection procedure.  Greedily build the best model that uses 1 and 2 features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (6.54450145202319, 6.080929821042619)\n",
      "1 (6.254188259087119, 7.0316161242486315)\n",
      "2 (6.175264325332599, 5.011468954357161)\n",
      "3 (6.77241514395342, 8.05896700143472)\n",
      "4 (6.4500896291443395, 5.699073737091736)\n",
      "5 (3.904394479751444, 7.06094634322534)\n",
      "6 (6.4327333258954775, 6.711889732232196)\n",
      "7 (6.7231709925124346, 7.5202012562811635)\n",
      "8 (6.702527550682737, 5.2393799182295036)\n",
      "9 (6.385343483090547, 4.306280609762139)\n",
      "10 (5.991213011661856, 5.45663431489543)\n",
      "11 (6.744151610668998, 5.401079183473508)\n",
      "12 (4.855105474674045, 3.7153181075195643)\n",
      "---\n",
      "0 12 (4.852984352935281, 3.656502213506232)\n",
      "1 12 (4.821917890519309, 3.6305325779158406)\n",
      "2 12 (4.86247179611612, 3.7815766252916707)\n",
      "3 12 (4.739192407784038, 3.5223765950957744)\n",
      "4 12 (4.864154127145216, 4.155276161233407)\n",
      "5 12 (3.801964159106713, 4.987002723682361)\n",
      "6 12 (4.808550904263029, 4.122281739573801)\n",
      "7 12 (4.766075205031166, 4.407518032588313)\n",
      "8 12 (4.869397194850256, 4.248970413678763)\n",
      "9 12 (4.83087570320003, 3.456127334865605)\n",
      "10 12 (4.44770797558722, 2.8770627416127232)\n",
      "11 12 (4.85015801277672, 3.502846738901483)\n"
     ]
    }
   ],
   "source": [
    "def train_and_eval_model(train_X, train_y, val_X, val_y):\n",
    "    ### Use sklearn's LinearRegression module \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    reg = LinearRegression().fit(train_X, train_y)\n",
    "    \n",
    "    ### Evaluate the performance with score, mean difference\n",
    "    train_y_hat = reg.predict(train_X)\n",
    "    val_y_hat = reg.predict(val_X)\n",
    "    \n",
    "    # return mean_difference on training and val\n",
    "    return (mean_difference(train_y, train_y_hat), mean_difference(val_y, val_y_hat))\n",
    "\n",
    "for i in range(0, X.shape[1]):\n",
    "    sub_train_X = train_X[:, i].reshape((-1,1))\n",
    "    sub_val_X = val_X[:, i].reshape((-1,1))\n",
    "    \n",
    "    print i, train_and_eval_model(sub_train_X, train_y, sub_val_X, val_y)\n",
    "    \n",
    "first_feat_selected_idx = 12\n",
    "\n",
    "print \"---\"\n",
    "for i in [i for i in range(0, X.shape[1]) if i != first_feat_selected_idx]:\n",
    "    sub_train_X = train_X[:, [i,first_feat_selected_idx]]\n",
    "    sub_val_X = val_X[:, [i, first_feat_selected_idx]]\n",
    "    \n",
    "    print i, first_feat_selected_idx, train_and_eval_model(sub_train_X, train_y, sub_val_X, val_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Consider following data that contains a user's salary, years of work experience, premium account status (0 or 1).  The data comes from J. Grus, Data Science from Scratch.\n",
    "\n",
    "Create a model using a regression.  Evaluate and characterize its performance.  \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(0.7,48000,1),(1.9,48000,0),(2.5,60000,1),(4.2,63000,0),(6,76000,0),(6.5,69000,0),(7.5,76000,0),(8.1,88000,0),(8.7,83000,1),(10,83000,1),(0.8,43000,0),(1.8,60000,0),(10,79000,1),(6.1,76000,0),(1.4,50000,0),(9.1,92000,0),(5.8,75000,0),(5.2,69000,0),(1,56000,0),(6,67000,0),(4.9,74000,0),(6.4,63000,1),(6.2,82000,0),(3.3,58000,0),(9.3,90000,1),(5.5,57000,1),(9.1,102000,0),(2.4,54000,0),(8.2,65000,1),(5.3,82000,0),(9.8,107000,0),(1.8,64000,0),(0.6,46000,1),(0.8,48000,0),(8.6,84000,1),(0.6,45000,0),(0.5,30000,1),(7.3,89000,0),(2.5,48000,1),(5.6,76000,0),(7.4,77000,0),(2.7,56000,0),(0.7,48000,0),(1.2,42000,0),(0.2,32000,1),(4.7,56000,1),(2.8,44000,1),(7.6,78000,0),(1.1,63000,0),(8,79000,1),(2.7,56000,0),(6,52000,1),(4.6,56000,0),(2.5,51000,0),(5.7,71000,0),(2.9,65000,0),(1.1,33000,1),(3,62000,0),(4,71000,0),(2.4,61000,0),(7.5,75000,0),(9.7,81000,1),(3.2,62000,0),(7.9,88000,0),(4.7,44000,1),(2.5,55000,0),(1.6,41000,0),(6.7,64000,1),(6.9,66000,1),(7.9,78000,1),(8.1,102000,0),(5.3,48000,1),(8.5,66000,1),(0.2,56000,0),(6,69000,0),(7.5,77000,0),(8,86000,0),(4.4,68000,0),(4.9,75000,0),(1.5,60000,0),(2.2,50000,0),(3.4,49000,1),(4.2,70000,0),(7.7,98000,0),(8.2,85000,0),(5.4,88000,0),(0.1,46000,0),(1.5,37000,0),(6.3,86000,0),(3.7,57000,0),(8.4,85000,0),(2,42000,0),(5.8,69000,1),(2.7,64000,0),(3.1,63000,0),(1.9,48000,0),(10,72000,1),(0.2,45000,0),(8.6,95000,0),(1.5,64000,0),(9.8,95000,0),(5.3,65000,0),(7.5,80000,0),(9.9,91000,0),(9.7,50000,1),(2.8,68000,0),(3.6,58000,0),(3.9,74000,0),(4.4,76000,0),(2.5,49000,0),(7.2,81000,0),(5.2,60000,1),(2.4,62000,0),(8.9,94000,0),(2.4,63000,0),(6.8,69000,1),(6.5,77000,0),(7,86000,0),(9.4,94000,0),(7.8,72000,1),(0.2,53000,0),(10,97000,0),(5.5,65000,0),(7.7,71000,1),(8.1,66000,1),(9.8,91000,0),(8,84000,0),(2.7,55000,0),(2.8,62000,0),(9.4,79000,0),(2.5,57000,0),(7.4,70000,1),(2.1,47000,0),(5.3,62000,1),(6.3,79000,0),(6.8,58000,1),(5.7,80000,0),(2.2,61000,0),(4.8,62000,0),(3.7,64000,0),(4.1,85000,0),(2.3,51000,0),(3.5,58000,0),(0.9,43000,0),(0.9,54000,0),(4.5,74000,0),(6.5,55000,1),(4.1,41000,1),(7.1,73000,0),(1.1,66000,0),(9.1,81000,1),(8,69000,1),(7.3,72000,1),(3.3,50000,0),(3.9,58000,0),(2.6,49000,0),(1.6,78000,0),(0.7,56000,0),(2.1,36000,1),(7.5,90000,0),(4.8,59000,1),(8.9,95000,0),(6.2,72000,0),(6.3,63000,0),(9.1,100000,0),(7.3,61000,1),(5.6,74000,0),(0.5,66000,0),(1.1,59000,0),(5.1,61000,0),(6.2,70000,0),(6.6,56000,1),(6.3,76000,0),(6.5,78000,0),(5.1,59000,0),(9.5,74000,1),(4.5,64000,0),(2,54000,0),(1,52000,0),(4,69000,0),(6.5,76000,0),(3,60000,0),(4.5,63000,0),(7.8,70000,0),(3.9,60000,1),(0.8,51000,0),(4.2,78000,0),(1.1,54000,0),(6.2,60000,0),(2.9,59000,0),(2.1,52000,0),(8.2,87000,0),(4.8,73000,0),(2.2,42000,1),(9.1,98000,0),(6.5,84000,0),(6.9,73000,0),(5.1,72000,0),(9.1,69000,1),(9.8,79000,1)]\n",
    "data = map(list, data) # change tuples to lists\n",
    "\n",
    "X = np.array([[1] + row[:2] for row in data]) # each element is [1, experience, salary]\n",
    "y = np.array([row[2] for row in data])   \n",
    "\n",
    "#print type(X), X.shape, type(y), y.shape\n",
    "N = int(0.8 * X.shape[0])\n",
    "train_X = X[:N,:]\n",
    "train_y = y[:N]\n",
    "val_X = X[N:,:]\n",
    "val_y = y[N:]\n",
    "\n",
    "reg = LinearRegression().fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Using the output from your model, make categorical predictions and then calculate the accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.8875\n",
      "Validation accuracy:  0.85\n"
     ]
    }
   ],
   "source": [
    "train_y_hat = 1 * (reg.predict(train_X) > 0.5)\n",
    "val_y_hat = 1 * (reg.predict(val_X) > 0.5)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print \"Training accuracy: \", accuracy_score(train_y, train_y_hat)\n",
    "print \"Validation accuracy: \", accuracy_score(val_y, val_y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ...\n",
      "Accuracy on training:  0.725\n",
      "Accuracy on validation:  0.8\n",
      "Neural Network Model\n",
      "Accuracy on training:  0.725\n",
      "Accuracy on validation:  0.8\n"
     ]
    }
   ],
   "source": [
    "### ADDED \n",
    "\n",
    "# Train a logistic model (i.e., sigmoid)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs').fit(train_X, train_y)\n",
    "\n",
    "### Evaluate the performance \n",
    "train_y_hat = 1 * (clf.predict(train_X) > 0.5)\n",
    "val_y_hat = 1 * (clf.predict(val_X) > 0.5)\n",
    "\n",
    "# print zip(train_y, train_y_hat)\n",
    "print \"Logistic Regression ...\"\n",
    "print \"Accuracy on training: \", accuracy_score(train_y, train_y_hat) \n",
    "print \"Accuracy on validation: \", accuracy_score(val_y, val_y_hat) \n",
    "\n",
    "# Train a neural network based regressor (i.e, output is linear node)...\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlr = MLPRegressor(max_iter=1000, hidden_layer_sizes=(50, 50, 5))\n",
    "mlr.fit(train_X, train_y)\n",
    "\n",
    "### Evaluate the performance with score, mean difference\n",
    "train_y_hat = 1 * (mlr.predict(train_X) > 0.5)\n",
    "val_y_hat = 1 * (mlr.predict(val_X) > 0.5)\n",
    "\n",
    "print \"Neural Network Model\"\n",
    "print \"Accuracy on training: \", accuracy_score(train_y, train_y_hat)  \n",
    "print \"Accuracy on validation: \", accuracy_score(val_y, val_y_hat) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "### ADDED \n",
    "\n",
    "# Those values look good but check out the actual predictions ... \n",
    "# ACCURACY ISN'T EVERYTHING, particularly if the data set is not balanced.\n",
    "\n",
    "print train_y_hat\n",
    "print val_y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
